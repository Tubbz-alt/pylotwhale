#!/usr/mprg/bin/python

import numpy as np
import pylab as pl
#import sys
import pandas as pd
import random
import ast
import matplotlib.pyplot as plt

"""
    Module for for the definition of sequences
    florencia @ 06.05.14

    Starting from a data frame and leading to the bigram counts.
    -- data frame --> data frames by recording (groupByRec + sortedRecDatFr)
    -- data frame --> time iterval distribution (plTimeIntervals)
    -- data frame --> sequences ()
    -- sequences --> bigram counts

"""


###########################################################
#####                     plotting                    #####
###########################################################


def plTimeIntervals(datB, plTitle='', outFig='', shuffl=0,
maxNTicks=False, TLims=(0, 19), frac=0, xLabel='ict [s]', yLabel='N'):
    """
    time interval distributions
    takes:
    < datB, data frame we whant to look into the time stamps
    < groupN, this is only given for the naming of the output plot
    < outFig, can be: outDir+"timeDistHist_%s.eps"%groupN
    * frac, display a line at the avlue of T below which frac*100%
            of the call pars are semarated, e.e, frac =0.75

    and returnsplots an histogram in the image folder

    """
    rec_datFrames, reccs = sortedRecDatFr(datB, shuff=shuffl)  # reccording data frames

    # time interval histogram
    interDist = {rec: rec_datFrames[rec].intervals.values for rec in rec_datFrames}  # intervals dictionary by reccording

    # interval ditribution
    allT = list(interDist.values())  # all interval values
    allT = np.asarray([item for subli in allT for item in subli])  # flattern the intervals
    allT.reshape((len(allT), 1))  # reshape for dictionary
    allT = allT[~np.isnan(allT)]  #filter nans out
    print np.shape(allT), allT.min(), allT.max()

     # histogram
    fig, ax = plt.subplots(figsize=(6,3))
    cax = ax.hist(allT[~np.isnan(allT)], bins=allT.max())
    ax.set_xlim(TLims)
    ax.set_xlabel(xLabel)
    ax.set_ylabel(yLabel)
    if maxNTicks: plt.locator_params(nbins=maxNTicks)

    if frac:
        Cumx = np.cumsum(cax[0])
        Tot = sum(cax[0])
        tbins = cax[1]
        ax.axvline(x=sum(Cumx <= Tot * frac), linewidth=4, color='r')
        print(("line at", sum(Cumx <= Tot * frac)))

    if plTitle: ax.set_title(plTitle)

    if outFig: fig.savefig( outFig, bbox_inches='tight')
    print("outFig:", outFig)

    #return fig, ax


def plTape(t, yRaw, plName='', scaleF = 20, lw = 0.05, title=''):
    """
    plots the calls vs. time
    """
    assert(len(t) == len(yRaw))

    freq_call = sorted([(yRaw.count(ucall), ucall) for ucall in
             np.unique(yRaw)], reverse=True, key=lambda x: x[0])  # sort calls
    i2c_tape = [thisCall[1] for thisCall in freq_call]
    c2i_tape = {i2c_tape[ix]: ix for ix in range(len(i2c_tape))}  # c2i
    #print np.unique(yRaw), c2i_tape, i
    #sys.exit()
    y = [c2i_tape[item] for item in yRaw]
    #print y[:5], i2c_tape, c2i_tape
    # plot

    #if not tapeN: tapeN = "%s%s%s"%(i2c_tape[0],len(i2c_tape), i2c_tape[-1])
    #figN = outDir+"tape_%s.pdf"%tapeN
    print(((t[-1] - t[0])/scaleF, np.min([np.max([1, len(freq_call) / 2]), 3])))
    fig = pl.figure(figsize=((t[-1] - t[0]) / scaleF, np.min([np.max([1, len(freq_call) / 2]), 3])))
    ax = fig.add_subplot(111)
    pl.plot(t, y, marker='|', lw=lw, markeredgewidth=1.5)
    ax.set_ylim(-0.5, len(c2i_tape))  # +0.1)
    ax.set_xlim(t[0] - 5, t[-1] + 5)
    ax.set_yticks(np.arange(len(c2i_tape)))
    ax.set_yticklabels(i2c_tape, fontsize=8)
    ax.set_xlabel('time [s]')
    ax.set_title(title)
    if plName: pl.savefig(plName)


def scattTape(t, yRaw, quality, plName='', scaleF=20, title=''):
    """
    Scatter plot of the calls in a tape, sorted acendinfgly with the
    frequence of the callS. the coulors represent the quality of the recording.
    yRaw must be a list
    """
    assert(len(t) == len(yRaw))
    q2i = {'A': 'k', 'B': 'b', 'C': 'g', 'D': 'r'}
    qual = [q2i[i] if i in q2i.keys() else 'gray' for i in quality]  # el: for different quality (buzz)

    freq_call = sorted([(yRaw.count(ucall), ucall) for ucall in np.unique(yRaw)], reverse=True, key=lambda x: x[0])  # inicialize
    i2c_tape = [thisCall[1] for thisCall in freq_call]
    c2i_tape = {i2c_tape[ix]: ix for ix in range(len(i2c_tape))}  # c2i

    print i2c_tape, len(qual), len(t)
    y = [c2i_tape[item] for item in yRaw]

    #plot
    print(t[-1]-t[0])/scaleF, np.min([np.max([1, len( freq_call )/2]), 3])
    fig, ax = plt.subplots(figsize=((t[-1]-t[0])/scaleF, np.min([np.max([1, len( freq_call )/2]), 3])))

    ax.scatter(t, y, marker='|', c=qual)
    ax.set_xlim(t[0] - 5, t[-1] + 5)
    ax.set_ylim(-0.5, len(c2i_tape))  # +0.1)
    ax.set_yticks(np.arange(len(c2i_tape)))  # ticks positions
    ax.set_yticklabels(i2c_tape, fontsize=8)  # ticks labels
    ax.set_xlabel('time [s]')
    ax.set_title(title)
    if plName: fig.savefig(plName)

###########################################################
#####              data base construciotin            #####
###########################################################

def timeS2secs(datFr, timeStName='time_stamp'):
    timeS = datFr[timeStName]
    timeSs = [60*60*int(tS.split('_')[0])+60*int(tS.split('_')[1])+int(tS.split('_')[-1]) for tS in timeS]
    return timeSs

###########################################################
#####          litsting, sorting and counting         #####
###########################################################

def groupByRec(dataFr, categ='recording'):
    """
    groups data by reccording
    returns:
    > 1 dictionary: recccordings --> indexes of the reccordings in same rec
    > 2 an array of with the reccordig names
    """
    recSetsD = dataFr.groupby(categ).groups #dictionary with the reccordings
    reccs = recSetsD.keys()
    print "#reccordings", len(recSetsD)
    return recSetsD, reccs


def sortedRecDatFr(dataFr, shuff = 0, categ='recording', sortL='timeSs'):
    """
    data frames for each reccording sorted temporally
    if shuff != 0 the time series are shuffled
    < categ - category into which we will separate the data
    < sortL - sorting label, the time stamp by default
    returns:
    > a dictionary of the data frames sorted sorted acendengly
    > an array of with the reccordig names
    """
    if(shuff):
        f = shuffleSeries
    else:
        f = lambda x: x

    recGr, reccs = groupByRec(dataFr, categ = categ)
    sortedRecsDF = {}

    for thisRec in recGr:
        recDatFr = dataFr.ix[ recGr[thisRec] ]  # select series
        recDatFr = f(recDatFr)  # shuffle or not
        recDatFr = recDatFr.sort(sortL)
        recDatFr['intervals'] = (recDatFr[sortL]-recDatFr[sortL].shift())  #compute intervals
        sortedRecsDF[thisRec] = recDatFr

    print "#reccordings", len(sortedRecsDF)
    return sortedRecsDF, reccs # data frames and labels


def shuffleSeries(dataFr, shuffleCol='timeSs'):
    """
    shuffles a series (shuffleCol) from a data frame:
    > data frame
    > name a of the column ti shuffle
    """
    x = dataFr[shuffleCol].values.copy()  # select series
    random.shuffle(x)  #shuffle
    shuffledRecs = dataFr.copy()  # new series
    shuffledRecs[shuffleCol] = x # set shuffled series

    return shuffledRecs # data frames and labels


def bigramCounts( li, adj0 = {}, call2index0 = {}, index2call0 = []):

    """
    sequences to dictionary of bigram counts
    list a list and returns:
    < li, sequence of tolkens, in for of a list
    > adj0, the adjacency 2D-dictionary of consecutive elements
    > the call to index dicitonary
    > the index to call list

    If an adjacency matrix is already given then we add the counts to it
    """

    ### CHECK INPUT
    assert( len(call2index0) == len(index2call0))# and len(adj0) >= len(call2index0) -1 )
    # dictionaries must have the same lenght and adj at least the same lenght - 1

    ### INICIALIZATIONS
    adj = adj0.copy()  # adjacenct dicitonary 
    call2index = call2index0.copy()  # call to index dict
    index2call = index2call0[:]  # index to call dict
    call_0='__INI' # previous call ini
    call_1='__END'  # end call
    sequence = li[:] # copy the list
    sequence.append(call_1) # add end tolken to li

    if len(call2index) == 0: # if empty dict
        print "inicializing"
        call2index[call_0] = 0
        call2index[call_1] = 1
        index2call.insert(0, call_0)  # inicialize it w/ __INI
        index2call.insert(1, call_1)  # inicialize it w/ __END

    n = len(index2call)  # init with the no. of calls in the dict.

    ### ITERATE OVER TOLKENS IN THE SEQUECE
    for call in sequence:
        if call not in call2index.keys():  # call in not in dict
            call2index[call] = n  # add call to dictionary
            index2call.insert(n, call)
            n += 1

        # adjacency dictionary
        if (call2index[call_0], call2index[call]) in adj.keys(): # plus one
            adj[call2index[call_0], call2index[call]] += 1
        else:
            adj[call2index[call_0], call2index[call]] = 1
        call_0 = call # reeset previous call

    return adj, call2index, index2call


def listOfSeqs( datB0, groupN=[], timeT=5, feature='call', shuffl=0):
    """
    list of sequences
    takes a data frame and returns a list of sequences
    ! assumes that the reccording names are not repeated. CHECK whether this holds
    < datB0, dataframe with the call (feature) and the timestamps
    < groupN = [], gives the option to create the list of sequences for
        various groups, without mixing the sequences accross groups
    > list of lists, where the lists are que sequences.
    """
    seqsLi = []
    for gr in groupN:
        '''
        defines the sequences
        '''
        datB = datB0.loc[datB0.group == gr]  # select group data
        rec_datFrames, reccs = sortedRecDatFr(datB, shuff=shuffl)  # dataframes by reccording sorted temporally
        seqsLi += [ seqsFromRec(rec_datFrames[rec], timeT, feature).sequences for rec in rec_datFrames ]  # list of sequences by rec

    thisGrSeqs = [item for sublist in seqsLi for item in sublist]  # flatter the list of sequecne so taht they are no longer separated by reccording
    return thisGrSeqs


def listOfSeqs2BigramCounts(li, M = {}, c2i = {}, i2c = []):
    """
    transforms a list(li) of sequences into bigram counts
    returns:
    beta - because inicializes the dicionaries from the calling of the function
    giving the chance countinue adding bigrams to existing counts
    > bigrma counts dictionary (M)
    > call to index dictionary (c2i)
    > index to call array (i2c)
    """

    for thisLi in li:
        M, c2i, i2c = bigramCounts(thisLi, M, c2i, i2c)#M2

    return (M, c2i, i2c)


###########################################################
#####             bigram analysis functions           #####
###########################################################

def normalize_2grams_dict(biGrmDict):
    """
    this funciton gets a bigram dictionary with the bigram counts
    and returns the normalized probablies

    Jul, 2014 (A)
    """

    assert( isinstance( biGrmDict, dict) )  # check input
    counts2grm = {i_x[0]: 0 for i_x in biGrmDict.keys()} # inicialize normalized dictionary w/ zeros

    # count the bigrams
    for A in counts2grm.keys(): # iterate the initial keys 'A'
        #print A
        for elem in biGrmDict.keys(): # iterate over the tuple key
            #print elem
            if elem[0] == A: counts2grm[A] += biGrmDict[elem]

    # normalize counts
    norm1_BiGrmDict = {}
    for elem in biGrmDict.keys():
        norm1_BiGrmDict[elem] = 1.0 * biGrmDict[elem] / counts2grm[elem[0]] if counts2grm[elem[0]] else np.nan

    return norm1_BiGrmDict

def select2grmsDict_lrgr_NotIni( datFr_li, lgr=5, removeSet=[0,1]):
    """
    selects the relevant labels from a bigram dictionary. Labels:
    - from the bigrams with more than lgr occurrences
    - not taking into account the __INI label
    - removeSet = [c2i['__INI'], c2i['__END']], list of indexes to leave out
    - the first line of the data frame contains the number of bigrams.
    > list of tuples, with the keys of the elements larger than lgr

    Jul, 2014 (B)
    """
    myProbs = datFr_li[ datFr_li > lgr ]  # larger than threshold
    
    litu = [ast.literal_eval(item) for item in myProbs.keys().values]  # string -> tuple
    no0 = litu[:]    
    for remItem in removeSet:
        no0 = [item for item in no0 if remItem not in item]  # filter out __INI, __END
    return no0

def plDistributionAndRealVal( dist, realVal = False, mu = False, h = False, nBins = 10, outFN='', plLabel='', plTitle='', maxNTicks = False):
    """
    Plots a the distribution (~histogram) of the distribution 'dist' and a line where the real value is

    Jul, 2014 (B)
    """
    #histogram
    Nvec, binVec = np.histogram( dist, bins = nBins )  # shuffled data histogram
    bincenters = 0.5*( binVec[1:] + binVec[:-1] )
    #pl.plot(bincenters, Nvec, 'b-')
    x = bincenters
    y = Nvec
    #print x, y
    pl.fill_between( x, y, alpha = 0.5)
    pl.plot(x,y, '.')
    if plLabel: pl.xlabel("%s"%plLabel)
    if plTitle: pl.title("%s"%plTitle)
    if maxNTicks: plt.locator_params(nbins=maxNTicks)


    # lines
    if realVal: pl.axvline( x = realVal, color='r', ls ='-', lw = 3.5)  # real value
    if mu: pl.axvline( x = mu, color='b', ls ='-', lw = 2)  # mean
    if h:
        pl.axvline( x = mu-h, color='b', ls ='--', lw = 2)  # left conf int
        pl.axvline( x = mu+h, color='b', ls ='--', lw = 2)  # right conf int

    if(outFN):
        print outFN
        pl.savefig(outFN, bbox_inches='tight')

def plDistributionAndRealVal_bar( dist, realVal = False, mu = False, h = False, nBins = 10, outFN='', plLabel='', plTitle=''):
    """
    Plots a the distribution (~histogram) of the distribution 'dist' and a line where the real value is

    Jul, 2014 (B)
    """
    #histogram
    pl.hist( dist, bins = nBins )  # shuffled data histogram
    #bincenters = 0.5*( binVec[1:] + binVec[:-1] )
    #pl.plot(bincenters, Nvec, 'b-')
    #x = bincenters
    #y = Nvec
    #print x, y
    #pl.fill_between( x, y, alpha = 0.5)
    #pl.plot(x,y, '.')
    if plLabel:
        pl.xlabel("%s"%plLabel)
    if plTitle:
        pl.title("%s"%plTitle)

    # lines
    if realVal: pl.axvline( x = realVal, color='r', ls ='-', lw = 3.5)  # real value
    if mu: pl.axvline( x = mu, color='b', ls ='-', lw = 2)  # mean
    if h:
        pl.axvline( x = mu-h, color='b', ls ='--', lw = 2)  # left conf int
        pl.axvline( x = mu+h, color='b', ls ='--', lw = 2)  # right conf int

    if(outFN):
        print outFN
        pl.savefig(outFN, bbox_inches='tight')


def adjBining( dists, Nbin0=5, minBinCont = 3, maxNbins=100 ):
    """
    finds the number of bins such that no bin gets less than minBinCont
    * dists, an array with the bigram probabilities of the shufflings

    Jul, 2014 (B)
    Nbin0 - stating number of bins
    minBinCont  - minimum number of elements per bin
    maxNbin - maximum number of bins
    """

    #Adjusting the bining
    n = Nbin0
    while True:
        n+=1
        Nvec = np.histogram( dists, bins = n )[0]  # shuffled data histogram
        if Nvec.min() < minBinCont or n > maxNbins:
            print n, Nvec.min()
            break


    return n-1


#################################################################
# OBJECTS
#################################################################

class seqsFromRec:
    """
    this class creates the sequences form a data frame with:
        * a single reccording
        * elements sorted temporally (out: sortedRecDatFr)
    """

    def __init__( self, data_frame, timeT = 5, feature ='call' ):

        self.dataFr = data_frame #one recording data frame,
        self.timeT = timeT
        self.feature = feature
        self.sequences = self.rec2seqs()

    def rec2seqs(self):
        """
        defines the sequences for each day-tape label
        """
        indx = self.dataFr.index
        #print "#calls", len(indx)
        seqs = []
        thisSeq = [ self.dataFr[self.feature].ix[indx[0]] ]  # the fist call in the rec

        for i in indx[1:]:
            if self.dataFr.ix[i].intervals <= self.timeT: # continue sequence
                thisSeq.append(self.dataFr[self.feature].ix[i])
            else: # new sequence
                seqs.append(thisSeq)
                thisSeq = [ self.dataFr[self.feature].ix[i]]

        seqs.append(thisSeq)

        return seqs


